[["index.html", "STATS5099 Data Mining and Machine Learning 1 Welcome to DMML Lab 2", " STATS5099 Data Mining and Machine Learning 1 Welcome to DMML Lab 2 In week 2, we have studied multidimensional scaling (MDS) to perform nonlinear dimension reduction. While MDS can be applied to any proximity data (i.e. similarity or dissimilarity), many R functions take the dissimilarity matrix as input. Therefore, the first step is always to check that the input data is a dissimilarity matrix and, if needed, convert any similarity matrix or data matrix into a dissimilarity matrix by using: # convert data matrix to dissimilarity dist(X) #X: a data object, where each row is an observation and each column is a variable # convert similarity to dissimilarity: library(smacof) sim2diss(s, method) #s: similarity matrix #method: see help page of sim2diss for details More information about the argument method in sim2diss can be found in Table 2 of the package vignette. According to the characteristics of the dissimilarity matrix, we then decide whether to apply classical MDS, metric MDS (including Sammon mapping), or non-metric MDS: # classical MDS cmdscale(d, k) #d: dissimilarity matrix; k: number of dimensions to be retained # Sammon mapping library(MASS) sammon(d, k) #d: dissimilarity matrix; k: number of dimensions to be retained # metric MDS library(smacof) mds(delta, type=c(&quot;ratio&quot;,&quot;interval&quot;) #delta: disimilarity matrix #When using &quot;ratio&quot;, the function f in metric MDS is chosen as f(x)=bx; #When using &quot;interval&quot;, the function f is chosen as f(x)=a+bx. # nonmetric MDS mds(delta, type=&quot;ordinal&quot;) #delta: disimilarity matrix #&#39;type=&quot;ordinal&#39; means the function f in non-metric MDS is a monotonic step function. One way to determine the number of dimensions for the new feature space is by using the scree plot, similar to Cattell's method for principal component analysis. For metric and non-metric MDS, the stress value can be extracted by using $stress. Finally, we can visualise the configuration points through scatterplots and evaluate goodness of MDS through Shepard diagrams: # scatterplot plot(mds.object) # Shepard diagram plot(mds.object, plot.type=&quot;Shepard&quot;) #mds.object: output of &#39;mds()&#39; "],["exercise-1-tasks-in-lecture-notes.html", "2 Exercise 1: Tasks in lecture notes", " 2 Exercise 1: Tasks in lecture notes Task 1: Perform the Sammon mapping on the crimes dataset using the command sammon from the MASS library and comment on the scatterplot. Hint The crimes dataset contains correlation between seven crime types, and therefore, the first step is to convert the correlation matrix into the dissimilarity matrix by using sim2dist(crimes, method=\"corr\"). After performing sammon mapping, configuration points are stored $points. "],["exercise-2-identifying-letters-of-alphabet.html", "3 Exercise 2: Identifying letters of alphabet", " 3 Exercise 2: Identifying letters of alphabet Wolford and Hollingsworth (1974) were interested in the confusions made when a person attempts to identify letters of the alphabet viewed for some milliseconds only. A confusion matrix was constructed that shows the frequency with which each stimulus letter was mistakenly called something else. A section of this matrix is shown in the table below. Letter B C D F G B -- C 3 -- D 7 5 -- F 3 5 7 -- G 7 12 2 2 -- The dataset is available from 'Datasets for week 2', under the name 'letter.csv'. The task is to visualise the letters as points in one/two/three dimensions and discover if there is anything interesting. Task 2 Is it appropriate to use principal component analysis to visualise the data? YesNo Is this dataset a dissimilarity matrix? YesNo Apply an appropriate MDS method to this data. How many dimensions would you keep? Comment on any pattern from the configuration plot. Hint If you would like to visualise the data in 3D, the following commands may be helpful. library(rgl) plot3d(...) text3d(...) Apart from the number of dimensions, have you introduced any other parameter(s) in your analysis? If so, study their influence by trying different values. Finally, as mentioned in the lecture note, MDS are sensitive to initial configurations. Try multiple initial configurations and compare the results. You may need to look into the help page of mds to find out how to change the initial configuration. "],["exercise-3-employment-in-europe.html", "4 Exercise 3: Employment in Europe", " 4 Exercise 3: Employment in Europe We have looked at European employment dataset in Lab 1. Let's now analyse this dataset again using MDS. MDS allows us to visualise how similar two countries are as well as visualising the variables. You may load the data by using the following command: employ &lt;- read.table(&quot;eurojob.txt&quot;, header=TRUE, row.names=1) Task 3 For this dataset, is it more appropriate to use the original variables or the standardised variables when calculating the distance matrix? original variablesstandardised variables Compute a distance matrix for visualising the countries and another distance matrix for visualising the variables. Which MDS method is more appropriate? metric MDSnon-metric MDS Apply an appropriate MDS method to this data and decide the number of dimensions to keep. Do you see any clusters when visualising the countries, or any country distinct from others? How would you interpret the plot on variables (i.e. variables as points)? "],["solutions.html", "5 Solutions 5.1 Task 1 5.2 Task 2 5.3 Task 3", " 5 Solutions 5.1 Task 1 The steps for implementing Sammon mapping are similar to implementing metric MDS, that is, we need to first convert the inter-correlations into a dissimilarity matrix and then apply the sammon command. library(MASS);library(smacof) crime.dist &lt;- sim2diss(crimes, method=&quot;corr&quot;) set.seed(1) crime.sm&lt;-sammon(crime.dist,k=2) ## Initial stress : 0.06663 ## stress after 10 iters: 0.02557, magic = 0.500 ## stress after 20 iters: 0.02554, magic = 0.500 plot(crime.sm$points,type=&quot;n&quot;,asp=1) text(crime.sm$points,labels=names(crimes)) The plot is quite similar to the result obtained from metric MDS, except that the distance between Murder and Assault increases slightly. 5.2 Task 2 The data is in a format of the proximity matrix rather than the data matrix. Therefore, PCA is not suitable. A larger value indicates that two letters are more likely to cause confusion and thus more similar. As this is a similarity matrix, the first step is to convert the data into a dissimilarity matrix. library(smacof) letter &lt;- read.csv(&quot;letter.csv&quot;, row.names=1) letter.dist &lt;- sim2diss(letter, method=max(letter)) #z-s_ij letter.dist &lt;- as.dist(letter.dist) letter.dist ## C D G H M N Q ## D 15 ## G 8 18 ## H 18 16 17 ## M 18 17 18 1 ## N 18 16 19 2 4 ## Q 11 0 11 19 18 12 ## W 19 15 18 15 2 7 16 Because we have deduced dissimilarities from similarities, the absolute dissimilarities \\(\\delta_ij\\) depend on the value of personally chosen \\(z\\). This is the case where the non-metric MDS makes most sense. #nonmetric MDS #2D set.seed(1) letter.nmds2 &lt;- mds(letter.dist, ndim=2, type=&quot;ordinal&quot;) plot(letter.nmds2,asp=1) plot(letter.nmds2,plot.type=&quot;Shepard&quot;) letter.nmds2$stress ## [1] 0.05971 # Kruskal (1964) gave following advise about stress values based on his experience: # Stress Goodness-of-fit # 0.200 poor # 0.100 fair # 0.050 good # 0.025 excellent # 0.000 perfect # More recent articles caution against using a table like this since acceptable values of stress depends on the quality of the distance matrix and the number of objects in that matrix. Let's try reducing the data to 3 dimensions. #3D set.seed(1) letter.nmds3 &lt;- mds(letter.dist, ndim=3, type=&quot;ordinal&quot;) library(rgl) ## ## Attaching package: &#39;rgl&#39; ## The following object is masked from &#39;package:plotrix&#39;: ## ## mtext3d # plot3d(letter.nmds3$conf[,1],letter.nmds3$conf[,2], # letter.nmds3$conf[,3],type=&quot;&quot;, # xlab=&quot;Axis 1&quot;,ylab=&quot;Axis 2&quot;,zlab=&quot;Axis 3&quot;,asp=1) text3d(letter.nmds3$conf[,1],letter.nmds3$conf[,2], letter.nmds3$conf[,3],texts=names(letter.dist),asp=1) plot(letter.nmds3,plot.type=&quot;Shepard&quot;) letter.nmds3$stress ## [1] 0.01758 To produce the scree plot, we need to compute the stress value for each dimension. N_dim &lt;- 1:(nrow(letter)-1) letter.nmds &lt;- matrix(nrow=length(N_dim),ncol=2) for (i in N_dim){ letter.nmds[i,1] &lt;- i letter.nmds[i,2] &lt;- mds(letter.dist, ndim=i, type=&quot;ordinal&quot;)$stress } plot(letter.nmds, type=&quot;b&quot;, main=&quot;scree plot&quot;, xlab=&quot;number of dimensions&quot;, ylab=&quot;stress-1&quot;) The scree plot suggests that using three dimensions could give a relatively small stress value. Based on the 3D plot in (c), one might argue that C, D, G, Q forms a cluster and H, M, N, W forms another cluster. When converting confusion to distance, we have introduced the parameter \\(z\\) (maximum value to be subtracted from). Now we will create a function to investigate the effect of \\(z\\). Z &lt;- seq(max(letter), by=1, length.out=100) letter.z &lt;- matrix(nrow=length(Z), ncol=2) for (i in 1:length(Z)){ letter.dist &lt;- sim2diss(letter, method=Z[i]) set.seed(1) letter.z[i,1] &lt;- Z[i] letter.z[i,2] &lt;- mds(letter.dist, ndim=3, type=&quot;ordinal&quot;)$stress } plot(letter.z, xlab=&quot;integer z&quot;, ylab=&quot;stress-1&quot;) It is clear that \\(z\\) has a large influence on the stress value. To test the sensitivity to initial configuration, we need to change the current way of initialisation, which is classical MDS by default. Specially, we need to use the argument: init=\"random\" Seed &lt;- 1:100 letter.seed &lt;- matrix(nrow=length(Seed), ncol=1) for (i in Seed){ letter.dist &lt;- sim2diss(letter, method=max(letter)) set.seed(i) letter.seed[i] &lt;- mds(letter.dist,ndim=3, type=&quot;ordinal&quot;, init=&quot;random&quot;)$stress } hist(letter.seed, xlab=&quot;stress value&quot;, main=&quot;Histogram of stress values computed over 100 random initialisations&quot;) 5.3 Task 3 As the variables have different variances, it would be better to use standardised variables when computing the pairwise distances. apply(employ,2,var) ## AGRIC MINING MANU POWER CONSTR SERVICE FINANCE SOCIAL ## 241.6958 0.9410 49.1087 0.1415 2.7080 20.9329 7.8768 46.6426 ## TRANS ## 1.9362 employ.sd &lt;- scale(employ) employ.dist &lt;- dist(employ.sd) #to visualise countries as data points employ.dist.var &lt;- dist(t(employ.sd)) #to visualise variables as data points As we have created the distance matrix directly from the data, metric MDS would be a better choice. There are three types of metric MDS covered in the lecture. Classical MDS (cmdscale) is omitted as it is equivalent to PCA (check that!) Metric MDS can be computed using mds. library(smacof) set.seed(1) employ.mds2 &lt;- mds(employ.dist, ndim=2, type=&quot;interval&quot;) plot(employ.mds2) plot(employ.mds2,plot.type=&quot;Shepard&quot;) The Shepard diagram suggests that a lot of information was lost when using only two dimensions. To select the optimal number of dimensions, scree plot is generated. employ.mds &lt;- matrix(nrow=nrow(employ)-1,ncol=2) for (i in 1:(nrow(employ)-1)){ employ.mds[i,1] &lt;- i set.seed(1) employ.mds[i,2] &lt;- mds(employ.dist, ndim=i, type=&quot;interval&quot;)$stress } plot(employ.mds, type=&quot;b&quot;, main=&quot;scree plot&quot;, xlab=&quot;number of dimensions&quot;, ylab=&quot;stress&quot;) Here is a difficult case where there is no clear cut-off point. Depending on the purpose of the study, 4-8 dimensions seem to be a reasonable range. When implementing Sammon mapping, there are a few differences which are explained below. #Sammon library(MASS) employ.sm &lt;- sammon(employ.dist, k=2) ## Initial stress : 0.12723 ## stress after 10 iters: 0.06316, magic = 0.092 ## stress after 20 iters: 0.04799, magic = 0.500 ## stress after 30 iters: 0.04667, magic = 0.500 ## stress after 40 iters: 0.04664, magic = 0.500 plot(employ.sm$points, type=&quot;n&quot;, xlab=&quot;Axis 1&quot;, ylab=&quot;Axis 2&quot;,asp=1) text(employ.sm$points, labels=names(employ.dist)) As sammon is not from the smacof library, we cannot easily plot the Shepard diagram by setting plot.type=\"Shepard\". Instead, an additional command Shepard is needed to produce the Shepard diagram. employ.sh&lt;-Shepard(employ.dist, employ.sm$points, p=2) plot(employ.sh, pch=&quot;.&quot;) lines(employ.sh$x, employ.sh$yf, type = &quot;S&quot;) There is no clear group structure when applying metric MDS or Sammon mapping on the dissimilarity matrix computed over countries. Turkey seems to locate slightly far away from the remaining countries. You can perform the above analysis again, but using employ.dist.var as the input to MDS methods. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
